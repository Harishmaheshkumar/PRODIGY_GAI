{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34219828-6be1-4109-9ccb-c82920d95ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97877689-f331-4500-8d1f-823a189ac788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a329f582-47b2-4915-be16-522270b13827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05834348-6be2-44ff-b9ce-15923deb964c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57734c5a-0149-43f3-a598-18889145ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99aeb2fe-56ad-49ea-bdc2-b888fa14206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0746a0d7-e1b0-4348-a2e5-eb3f3f2dee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"i am really impressed\"\n",
    "max_length = 128\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30c6da94-77cc-4517-8f1b-c6b2a6e9c95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   72,   716,  1107, 12617]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95d93cf7-d165-4ae3-931c-2d0ab2392a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids['input_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "022b07db-094a-4d59-b4df-c0e1135e0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=max_length, num_beams=5, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5c377dd-a9f7-4c10-a5be-231c3e44a95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   72,   716,  1107, 12617,   351,   262,  3081,   286,   262,  1720,\n",
       "           290,   262,  6491,  2139,    13,   198,   198, 15322,   642,   503,\n",
       "           286,   642,   416, 19200,   422,  3878,  1720,     0,   314,   423,\n",
       "           587,  1262,   428,  1720,   329,   625,   257,   614,   783,   290,\n",
       "           314,   423,  1239,   550,   257,  1917,   351,   340,    13,   314,\n",
       "           423,   587,  1262,   428,  1720,   329,   625,   257,   614,   783,\n",
       "           290,   314,   423,  1239,   550,   257,  1917,   351,   340,    13,\n",
       "           314,   423,   587,  1262,   428,  1720,   329,   625,   257,   614,\n",
       "           783,   290,   314,   423,  1239,   550,   257,  1917,   351,   340,\n",
       "            13,   314,   423,   587,  1262,   428,  1720,   329,   625,   257,\n",
       "           614,   783,   290,   314,   423,  1239,   550,   257,  1917,   351,\n",
       "           340,    13,   314,   423,   587,  1262,   428,  1720,   329,   625,\n",
       "           257,   614,   783,   290,   314,   423,  1239,   550]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35cea36c-9a4e-4324-a7f0-00796d4e61b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am really impressed with the quality of the product and the customer service.\n",
      "\n",
      "Rated 5 out of 5 by Anonymous from Great product! I have been using this product for over a year now and I have never had a problem with it. I have been using this product for over a year now and I have never had a problem with it. I have been using this product for over a year now and I have never had a problem with it. I have been using this product for over a year now and I have never had a problem with it. I have been using this product for over a year now and I have never had\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80b7f6bf-20b6-45cd-bc8b-c7cd454fed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i am really impressed with the quality of the product and the customer service.\\n\\nRated 5 out of 5 by Anonymous from Great product! I have been using this product for over a year now and I am very pleased with it. It is very easy to use and works great. I would recommend it to anyone who is looking for a product that will last a long time.<|endoftext|>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=max_length, num_beams=5,\n",
    "                        do_sample=False, no_repeat_ngram_size=2)\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db01d588-55f5-43f9-bc3c-239ebb034ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUCLUES SEARCH \n",
    "\n",
    "#BELOWE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6871caa7-d180-44f9-80ad-69feb89ea5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'welcome to KGP Talkie Tutorials,\\n              We will talk about machine learning, deep learning, neural networks and the machine learning applications that is currently going on in KGP News at KGP. We will go into deep learning basics and how we can use it in a practical manner. We will explore both public and private KGP systems to see how things are going. We will use the Machine Learning Toolbox to learn these applications and apply them to real problems. We are going to see how these applications can be applied to many different parts of KGP like the'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = '''welcome to KGP Talkie Tutorials,\n",
    "              We will talk about machine learning'''\n",
    "max_length = 128\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
    "input_ids = input_ids['input_ids'].to(device)\n",
    "\n",
    "output = model.generate(input_ids, max_length=max_length,\n",
    "                        do_sample=True, top_p=1)\n",
    "tokenizer.decode(output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
